import asyncio

import streamlit as st

from src.llm import LLM, GeminiLLM
from src.model import Message
from supabase_rag.client import SupabaseClient
from supabase_rag.embedding import OpenAIEmbedding
from supabase_rag.insert import InsertSupabase
from supabase_rag.rag import Rag, RagV1
from supabase_rag.search import SearchSupabase


def chat_page(rag: Rag, llm: LLM):
    """ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãƒšãƒ¼ã‚¸"""
    st.subheader("ğŸ’¬ Chatbot")

    if prompt := st.chat_input("ä½•ã‹ãŠå›°ã‚Šã§ã™ã‹ï¼Ÿ"):
        st.session_state.chat_history.append(Message(role="user", content=prompt))

        for message in st.session_state.chat_history:
            with st.chat_message(message.role):
                st.markdown(message.content)

        with st.chat_message("assistant"):
            placeholder = st.empty()
            rag_result = asyncio.run(rag.search(prompt, "å…¨å­¦æ•™è‚²æ¨é€²æ©Ÿæ§‹"))
            st.write(rag_result)
            response = llm.get_response_with_context(
                st.session_state.chat_history, placeholder, rag_result
            )

        st.session_state.chat_history.append(
            Message(role="assistant", content=response)
        )


def explanation_page():
    """æ¦‚è¦ã®ãƒšãƒ¼ã‚¸"""
    st.subheader("æ¦‚è¦")
    st.write(
        "ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€RAGãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦å±¥ä¿®ç™»éŒ²æ”¯æ´ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’å®Ÿè£…ã—ãŸã‚‚ã®ã§ã™ã€‚"
    )
    st.write("ä»¥ä¸‹ã®æ©Ÿèƒ½ãŒã‚ã‚Šã¾ã™ã€‚")
    st.write("- å±¥ä¿®ç™»éŒ²æ”¯æ´ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    st.write("- RAGãƒ‡ãƒ¼ã‚¿ã®é–²è¦§(ä¸€æ—¦ã€åŸºç¤å·¥å­¦éƒ¨3å¹´ç§‹å†¬ã®æˆæ¥­ã®ã¿)")
    st.write("- å±¥ä¿®ç™»éŒ²ä»¥å¤–ã®ã“ã¨ã«ã¯ç­”ãˆãªã„")
    st.write("- ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹æˆæ¥­ä»¥å¤–ã«ã¤ã„ã¦ã¯ç­”ãˆãªã„(å­˜åœ¨ã—ãªã„æˆæ¥­ã¯ç­”ãˆãªã„)")

    st.subheader("å…¥å‡ºåŠ›ä¾‹")
    with st.chat_message("user"):
        st.markdown("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å­¦ã¹ã‚‹æˆæ¥­ã‚’æ•™ãˆã¦")
    with st.chat_message("assistant"):
        st.markdown(
            """
                åŸºç¤å·¥å­¦éƒ¨ã§é–‹è¬›ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å­¦ã¹ã‚‹æˆæ¥­ã¯ã€ç§‘ç›®ç•ªå·90046ã®ã€Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã§ã™ã€‚ã“ã®æˆæ¥­ã¯ç§‹ï½å†¬å­¦æœŸã«ç«æ›œ4é™ã«è¡Œã‚ã‚Œã€3,4å¹´ç”ŸãŒå¯¾è±¡ã§ã™ã€‚
                
                ã€Œãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã§ã¯ã€å®Ÿä¸–ç•Œã‹ã‚‰åé›†ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰å…±æœ‰ã§ãã‚‹ã‚ˆã†çµ±åˆã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«é–¢ã™ã‚‹åŸºæœ¬çš„ãªæ¦‚å¿µã‚’å­¦ã³ã¾ã™ã€‚ã¾ãŸã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ“ä½œè¨€èªã¨ã—ã¦æ¨™æº–çš„ãªï¼³ï¼±ï¼¬ã®å®Ÿç¿’ã‚‚è¡Œã„ã¾ã™ã€‚
                
                ãŸã ã—ã€ã“ã®æˆæ¥­ã¯è¨ˆç®—æ©Ÿç§‘å­¦ã‚³ãƒ¼ã‚¹ã€ãŠã‚ˆã³ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ç§‘å­¦ã‚³ãƒ¼ã‚¹ä»¥å¤–ã®å­¦ç”Ÿã®å±¥ä¿®ã¯åŸå‰‡èªã‚ã‚‰ã‚Œã¦ã„ã¾ã›ã‚“ã®ã§ã”æ³¨æ„ãã ã•ã„ã€‚ã¾ãŸã€æˆæ¥­æ™‚é–“ä¸­ã«æ•°å›ã€æ¼”ç¿’å®¤ã§ã®æ¼”ç¿’ãŒã‚ã‚‹ãŸã‚ã€ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°Cã€ã€ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°Dã€ã¾ãŸã¯ã€Œæ¼”ç¿’Cã€ã‚’å—è¬›ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚
            """
        )


async def initialize() -> tuple[RagV1, LLM]:
    """session_stateã®åˆæœŸåŒ–"""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    client = SupabaseClient()
    insert_client = await InsertSupabase.new(client)
    search_client = await SearchSupabase.new(client)
    embedding_client = OpenAIEmbedding()
    rag = RagV1(insert_client, search_client, embedding_client)
    llm = GeminiLLM()

    return rag, llm


if __name__ == "__main__":
    rag_client, llm_client = asyncio.run(initialize())

    # ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2 = st.tabs(["ğŸ’¬ Chatbot", "ğŸ“š æ¦‚è¦"])

    # ã‚¿ãƒ–ã®åˆ‡ã‚Šæ›¿ãˆ
    with tab1:
        chat_page(rag_client, llm_client)

    with tab2:
        explanation_page()
